\section{Parallel Threading Algorithm}
In order to parallelise the transposition algorithm, the transposition is completed one row at a time in a separate thread. In order to avoid swapping elements which have already been swapped, the algorithm makes use of a nested \verb|for| loop with a depth of two. The outer loop row counter \verb|i| runs through every row, and the inner loop counter for the columns begins at \verb|j=i+1|. 

\subsection{PThreads}

\subsection{OpenMP}

\section{Block Transposition Algorithm}
The Block Transposition algorithm completes the process by swaping two blocks and then each block is transposed. This is shown to result in transposition as shown below:
$$ \begin{bmatrix}
A & B \\ 
C & D
\end{bmatrix} ^T
= 
\begin{bmatrix}
\begin{bmatrix}
A\\ 
C
\end{bmatrix} ^T \\ 
\begin{bmatrix}
B
\\ 
D
\end{bmatrix} ^T
\end{bmatrix}

= 

\begin{bmatrix}
A^T & C^T \\ 
B^T & D^T
\end{bmatrix}
$$

\subsection{PThreads}

Creating this operation using PThreads, each block $B_{ij}$ of 2 x 2 matrix elements are assigned to a thread and is swapped with the corresponding block $B_{ji}$. Once this operation has been completed, two more child threads are spawned to transpose $B_{ij}$ and $B_{ji}$.

\subsection{OpenMP}
The parallelisation using OpenMP involves parallelising the block operations. Each thread uses additional parallelisation to swap $B_{ij}$ and $B_{ji} and subsiquently each transposition is parallelised. 